{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "NNahxEi-kfZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[0,1],[2,6],[3,8]]) #x1, x2\n",
        "y = np.array([1,1,4])\n",
        "\n",
        "x_b = np.c_[np.ones((x.shape[0],1)),x]"
      ],
      "metadata": {
        "id": "gUvtq5llkeLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(theta, x, y):\n",
        "    y_hat = x.dot(theta)\n",
        "    c = (1/(2*x.shape[0])) * np.sum((y_hat - y) ** 2)  # Use x.shape[0] to get N\n",
        "    return c"
      ],
      "metadata": {
        "id": "WM9sss42j9zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stochastic GD**"
      ],
      "metadata": {
        "id": "r6JXuyjZj36Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rV292LDjz4l"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(alpha, x, y, ep=0.001, max_iter=10000):\n",
        "    converged = False\n",
        "    iter = 0\n",
        "    N = x.shape[0]  # number of samples\n",
        "    print(\"Num of data =\", N)\n",
        "\n",
        "    # initial theta\n",
        "    theta = np.random.random((x.shape[1], 1))\n",
        "    print(\"Init theta.shape =\", theta.shape)\n",
        "\n",
        "    # total error, J(theta)\n",
        "    J = cost_function(theta, x, y)\n",
        "    print(\"First J =\", J)\n",
        "\n",
        "    while not converged:\n",
        "        # Shuffle the data at the beginning of each epoch\n",
        "        indices = np.random.permutation(N)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        for i in range(N):\n",
        "            # Select one training example\n",
        "            x_i = x[i].reshape(1, -1)\n",
        "            y_i = y[i].reshape(-1, 1)\n",
        "\n",
        "            # Calculate the prediction\n",
        "            y_hat = x_i.dot(theta)\n",
        "\n",
        "            # Calculate the gradient\n",
        "            diff = y_hat - y_i\n",
        "            grad = x_i.T.dot(diff)\n",
        "\n",
        "            # Update the parameters\n",
        "            theta = theta - alpha * grad\n",
        "\n",
        "            assert theta.shape == (x.shape[1], 1)\n",
        "\n",
        "            # Compute the cost with the updated theta\n",
        "            J2 = cost_function(theta, x, y)\n",
        "\n",
        "            # Check for convergence\n",
        "            if abs(J - J2) <= ep:\n",
        "                print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n",
        "                converged = True\n",
        "                break\n",
        "\n",
        "            J = J2\n",
        "            iter += 1\n",
        "\n",
        "            if iter == max_iter:\n",
        "                print('       Max iterations exceeded!')\n",
        "                converged = True\n",
        "                break\n",
        "\n",
        "    return theta\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    print(\"start main\")\n",
        "    print(x_b.shape)\n",
        "    y = y.reshape(-1, 1)\n",
        "    print(y.shape)\n",
        "\n",
        "    alpha = 0.01  # learning rate\n",
        "    # Training process\n",
        "    theta = stochastic_gradient_descent(alpha, x_b, y, ep=0.000000000001, max_iter=1000000)\n",
        "    print(\"Theta =\", theta)\n",
        "\n",
        "    # Predict trained x\n",
        "    xtest = np.array([[4, 9]])\n",
        "    xtest_b = np.c_[np.ones((xtest.shape[0], 1)), xtest]\n",
        "    y_p = xtest_b.dot(theta)\n",
        "    print(\"y predict =\", y_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx8CtejBkAZ2",
        "outputId": "10dbbec5-1405-4478-a7d5-7a27af59ba47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start main\n",
            "(3, 3)\n",
            "(3, 1)\n",
            "Num of data = 3\n",
            "Init theta.shape = (3, 1)\n",
            "First J = 5.9193094502980985\n",
            "       Converged, iterations:  202044 / 1000000\n",
            "Theta = [[ 6.99670569]\n",
            " [14.99290677]\n",
            " [-5.99700918]]\n",
            "y predict = [[12.99525014]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mini-Batch GD**"
      ],
      "metadata": {
        "id": "xEUGV2zZkCXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_batch_gradient_descent(alpha, x, y, batch_size=2, ep=0.001, max_iter=10000):\n",
        "    converged = False\n",
        "    iter = 0\n",
        "    N = x.shape[0]  # number of samples\n",
        "    print(\"Num of data =\", N)\n",
        "\n",
        "    # initial theta\n",
        "    theta = np.random.random((x.shape[1], 1))\n",
        "    print(\"Init theta.shape =\", theta.shape)\n",
        "\n",
        "    # total error, J(theta)\n",
        "    J = cost_function(theta, x, y)\n",
        "    print(\"First J =\", J)\n",
        "\n",
        "    while not converged:\n",
        "        # Shuffle the data at the beginning of each epoch\n",
        "        indices = np.random.permutation(N)\n",
        "        x = x[indices]\n",
        "        y = y[indices]\n",
        "\n",
        "        for i in range(0, N, batch_size):\n",
        "            # Select mini-batch\n",
        "            x_i = x[i:i+batch_size]\n",
        "            y_i = y[i:i+batch_size].reshape(-1, 1)\n",
        "\n",
        "            # Calculate the prediction\n",
        "            y_hat = x_i.dot(theta)\n",
        "\n",
        "            # Calculate the gradient\n",
        "            diff = y_hat - y_i\n",
        "            grad = x_i.T.dot(diff) / batch_size\n",
        "\n",
        "            # Update the parameters\n",
        "            theta = theta - alpha * grad\n",
        "\n",
        "            assert theta.shape == (x.shape[1], 1)\n",
        "\n",
        "        # Compute the cost with the updated theta\n",
        "        J2 = cost_function(theta, x, y)\n",
        "\n",
        "        # Check for convergence\n",
        "        if abs(J - J2) <= ep:\n",
        "            print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n",
        "            converged = True\n",
        "\n",
        "        J = J2\n",
        "        iter += 1\n",
        "\n",
        "        if iter == max_iter:\n",
        "            print('       Max iterations exceeded!')\n",
        "            converged = True\n",
        "\n",
        "    return theta\n"
      ],
      "metadata": {
        "id": "X3rgXLO_kFA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    print(\"start main\")\n",
        "    print(x_b.shape)\n",
        "    y = y.reshape(-1, 1)\n",
        "    print(y.shape)\n",
        "\n",
        "    alpha = 0.01  # learning rate\n",
        "    # Training process\n",
        "    theta = mini_batch_gradient_descent(alpha, x_b, y, batch_size=2, ep=0.000000000001, max_iter=1000000)\n",
        "    print(\"Theta =\", theta)\n",
        "\n",
        "    # Predict trained x\n",
        "    xtest = np.array([[4, 9]])\n",
        "    xtest_b = np.c_[np.ones((xtest.shape[0], 1)), xtest]\n",
        "    y_p = xtest_b.dot(theta)\n",
        "    print(\"y predict =\", y_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjkHQoHkIlC",
        "outputId": "1c940ff6-30da-4244-e813-b09f715cbea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start main\n",
            "(3, 3)\n",
            "(3, 1)\n",
            "Num of data = 3\n",
            "Init theta.shape = (3, 1)\n",
            "First J = 7.514786557797791\n",
            "       Converged, iterations:  137180 / 1000000\n",
            "Theta = [[ 6.99303046]\n",
            " [14.98478705]\n",
            " [-5.99354833]]\n",
            "y predict = [[12.99024366]]\n"
          ]
        }
      ]
    }
  ]
}